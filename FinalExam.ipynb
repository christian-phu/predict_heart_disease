{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FinalExam.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**DATA PROCESSING**"
      ],
      "metadata": {
        "id": "a5B8j4Up5Az9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import libraries\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "Dq0OLX5xnmBK"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Upload dataset\n",
        "\n",
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "jC6Rf0GfnmOK",
        "outputId": "82e05e49-a304-4926-b051-19716ea0bae6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-0a6698af-7088-4bef-be97-277e7fabdea4\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-0a6698af-7088-4bef-be97-277e7fabdea4\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving heart.csv to heart (5).csv\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'heart.csv': b'\\xef\\xbb\\xbfage,sex,cp,trestbps,chol,fbs,restecg,thalach,exang,oldpeak,slope,ca,thal,target\\r\\n63,1,3,145,233,1,0,150,0,2.3,0,0,1,1\\r\\n37,1,2,130,250,0,1,187,0,3.5,0,0,2,1\\r\\n41,0,1,130,204,0,0,172,0,1.4,2,0,2,1\\r\\n56,1,1,120,236,0,1,178,0,0.8,2,0,2,1\\r\\n57,0,0,120,354,0,1,163,1,0.6,2,0,2,1\\r\\n57,1,0,140,192,0,1,148,0,0.4,1,0,1,1\\r\\n56,0,1,140,294,0,0,153,0,1.3,1,0,2,1\\r\\n44,1,1,120,263,0,1,173,0,0,2,0,3,1\\r\\n52,1,2,172,199,1,1,162,0,0.5,2,0,3,1\\r\\n57,1,2,150,168,0,1,174,0,1.6,2,0,2,1\\r\\n54,1,0,140,239,0,1,160,0,1.2,2,0,2,1\\r\\n48,0,2,130,275,0,1,139,0,0.2,2,0,2,1\\r\\n49,1,1,130,266,0,1,171,0,0.6,2,0,2,1\\r\\n64,1,3,110,211,0,0,144,1,1.8,1,0,2,1\\r\\n58,0,3,150,283,1,0,162,0,1,2,0,2,1\\r\\n50,0,2,120,219,0,1,158,0,1.6,1,0,2,1\\r\\n58,0,2,120,340,0,1,172,0,0,2,0,2,1\\r\\n66,0,3,150,226,0,1,114,0,2.6,0,0,2,1\\r\\n43,1,0,150,247,0,1,171,0,1.5,2,0,2,1\\r\\n69,0,3,140,239,0,1,151,0,1.8,2,2,2,1\\r\\n59,1,0,135,234,0,1,161,0,0.5,1,0,3,1\\r\\n44,1,2,130,233,0,1,179,1,0.4,2,0,2,1\\r\\n42,1,0,140,226,0,1,178,0,0,2,0,2,1\\r\\n61,1,2,150,243,1,1,137,1,1,1,0,2,1\\r\\n40,1,3,140,199,0,1,178,1,1.4,2,0,3,1\\r\\n71,0,1,160,302,0,1,162,0,0.4,2,2,2,1\\r\\n59,1,2,150,212,1,1,157,0,1.6,2,0,2,1\\r\\n51,1,2,110,175,0,1,123,0,0.6,2,0,2,1\\r\\n65,0,2,140,417,1,0,157,0,0.8,2,1,2,1\\r\\n53,1,2,130,197,1,0,152,0,1.2,0,0,2,1\\r\\n41,0,1,105,198,0,1,168,0,0,2,1,2,1\\r\\n65,1,0,120,177,0,1,140,0,0.4,2,0,3,1\\r\\n44,1,1,130,219,0,0,188,0,0,2,0,2,1\\r\\n54,1,2,125,273,0,0,152,0,0.5,0,1,2,1\\r\\n51,1,3,125,213,0,0,125,1,1.4,2,1,2,1\\r\\n46,0,2,142,177,0,0,160,1,1.4,0,0,2,1\\r\\n54,0,2,135,304,1,1,170,0,0,2,0,2,1\\r\\n54,1,2,150,232,0,0,165,0,1.6,2,0,3,1\\r\\n65,0,2,155,269,0,1,148,0,0.8,2,0,2,1\\r\\n65,0,2,160,360,0,0,151,0,0.8,2,0,2,1\\r\\n51,0,2,140,308,0,0,142,0,1.5,2,1,2,1\\r\\n48,1,1,130,245,0,0,180,0,0.2,1,0,2,1\\r\\n45,1,0,104,208,0,0,148,1,3,1,0,2,1\\r\\n53,0,0,130,264,0,0,143,0,0.4,1,0,2,1\\r\\n39,1,2,140,321,0,0,182,0,0,2,0,2,1\\r\\n52,1,1,120,325,0,1,172,0,0.2,2,0,2,1\\r\\n44,1,2,140,235,0,0,180,0,0,2,0,2,1\\r\\n47,1,2,138,257,0,0,156,0,0,2,0,2,1\\r\\n53,0,2,128,216,0,0,115,0,0,2,0,0,1\\r\\n53,0,0,138,234,0,0,160,0,0,2,0,2,1\\r\\n51,0,2,130,256,0,0,149,0,0.5,2,0,2,1\\r\\n66,1,0,120,302,0,0,151,0,0.4,1,0,2,1\\r\\n62,1,2,130,231,0,1,146,0,1.8,1,3,3,1\\r\\n44,0,2,108,141,0,1,175,0,0.6,1,0,2,1\\r\\n63,0,2,135,252,0,0,172,0,0,2,0,2,1\\r\\n52,1,1,134,201,0,1,158,0,0.8,2,1,2,1\\r\\n48,1,0,122,222,0,0,186,0,0,2,0,2,1\\r\\n45,1,0,115,260,0,0,185,0,0,2,0,2,1\\r\\n34,1,3,118,182,0,0,174,0,0,2,0,2,1\\r\\n57,0,0,128,303,0,0,159,0,0,2,1,2,1\\r\\n71,0,2,110,265,1,0,130,0,0,2,1,2,1\\r\\n54,1,1,108,309,0,1,156,0,0,2,0,3,1\\r\\n52,1,3,118,186,0,0,190,0,0,1,0,1,1\\r\\n41,1,1,135,203,0,1,132,0,0,1,0,1,1\\r\\n58,1,2,140,211,1,0,165,0,0,2,0,2,1\\r\\n35,0,0,138,183,0,1,182,0,1.4,2,0,2,1\\r\\n51,1,2,100,222,0,1,143,1,1.2,1,0,2,1\\r\\n45,0,1,130,234,0,0,175,0,0.6,1,0,2,1\\r\\n44,1,1,120,220,0,1,170,0,0,2,0,2,1\\r\\n62,0,0,124,209,0,1,163,0,0,2,0,2,1\\r\\n54,1,2,120,258,0,0,147,0,0.4,1,0,3,1\\r\\n51,1,2,94,227,0,1,154,1,0,2,1,3,1\\r\\n29,1,1,130,204,0,0,202,0,0,2,0,2,1\\r\\n51,1,0,140,261,0,0,186,1,0,2,0,2,1\\r\\n43,0,2,122,213,0,1,165,0,0.2,1,0,2,1\\r\\n55,0,1,135,250,0,0,161,0,1.4,1,0,2,1\\r\\n51,1,2,125,245,1,0,166,0,2.4,1,0,2,1\\r\\n59,1,1,140,221,0,1,164,1,0,2,0,2,1\\r\\n52,1,1,128,205,1,1,184,0,0,2,0,2,1\\r\\n58,1,2,105,240,0,0,154,1,0.6,1,0,3,1\\r\\n41,1,2,112,250,0,1,179,0,0,2,0,2,1\\r\\n45,1,1,128,308,0,0,170,0,0,2,0,2,1\\r\\n60,0,2,102,318,0,1,160,0,0,2,1,2,1\\r\\n52,1,3,152,298,1,1,178,0,1.2,1,0,3,1\\r\\n42,0,0,102,265,0,0,122,0,0.6,1,0,2,1\\r\\n67,0,2,115,564,0,0,160,0,1.6,1,0,3,1\\r\\n68,1,2,118,277,0,1,151,0,1,2,1,3,1\\r\\n46,1,1,101,197,1,1,156,0,0,2,0,3,1\\r\\n54,0,2,110,214,0,1,158,0,1.6,1,0,2,1\\r\\n58,0,0,100,248,0,0,122,0,1,1,0,2,1\\r\\n48,1,2,124,255,1,1,175,0,0,2,2,2,1\\r\\n57,1,0,132,207,0,1,168,1,0,2,0,3,1\\r\\n52,1,2,138,223,0,1,169,0,0,2,4,2,1\\r\\n54,0,1,132,288,1,0,159,1,0,2,1,2,1\\r\\n45,0,1,112,160,0,1,138,0,0,1,0,2,1\\r\\n53,1,0,142,226,0,0,111,1,0,2,0,3,1\\r\\n62,0,0,140,394,0,0,157,0,1.2,1,0,2,1\\r\\n52,1,0,108,233,1,1,147,0,0.1,2,3,3,1\\r\\n43,1,2,130,315,0,1,162,0,1.9,2,1,2,1\\r\\n53,1,2,130,246,1,0,173,0,0,2,3,2,1\\r\\n42,1,3,148,244,0,0,178,0,0.8,2,2,2,1\\r\\n59,1,3,178,270,0,0,145,0,4.2,0,0,3,1\\r\\n63,0,1,140,195,0,1,179,0,0,2,2,2,1\\r\\n42,1,2,120,240,1,1,194,0,0.8,0,0,3,1\\r\\n50,1,2,129,196,0,1,163,0,0,2,0,2,1\\r\\n68,0,2,120,211,0,0,115,0,1.5,1,0,2,1\\r\\n69,1,3,160,234,1,0,131,0,0.1,1,1,2,1\\r\\n45,0,0,138,236,0,0,152,1,0.2,1,0,2,1\\r\\n50,0,1,120,244,0,1,162,0,1.1,2,0,2,1\\r\\n50,0,0,110,254,0,0,159,0,0,2,0,2,1\\r\\n64,0,0,180,325,0,1,154,1,0,2,0,2,1\\r\\n57,1,2,150,126,1,1,173,0,0.2,2,1,3,1\\r\\n64,0,2,140,313,0,1,133,0,0.2,2,0,3,1\\r\\n43,1,0,110,211,0,1,161,0,0,2,0,3,1\\r\\n55,1,1,130,262,0,1,155,0,0,2,0,2,1\\r\\n37,0,2,120,215,0,1,170,0,0,2,0,2,1\\r\\n41,1,2,130,214,0,0,168,0,2,1,0,2,1\\r\\n56,1,3,120,193,0,0,162,0,1.9,1,0,3,1\\r\\n46,0,1,105,204,0,1,172,0,0,2,0,2,1\\r\\n46,0,0,138,243,0,0,152,1,0,1,0,2,1\\r\\n64,0,0,130,303,0,1,122,0,2,1,2,2,1\\r\\n59,1,0,138,271,0,0,182,0,0,2,0,2,1\\r\\n41,0,2,112,268,0,0,172,1,0,2,0,2,1\\r\\n54,0,2,108,267,0,0,167,0,0,2,0,2,1\\r\\n39,0,2,94,199,0,1,179,0,0,2,0,2,1\\r\\n34,0,1,118,210,0,1,192,0,0.7,2,0,2,1\\r\\n47,1,0,112,204,0,1,143,0,0.1,2,0,2,1\\r\\n67,0,2,152,277,0,1,172,0,0,2,1,2,1\\r\\n52,0,2,136,196,0,0,169,0,0.1,1,0,2,1\\r\\n74,0,1,120,269,0,0,121,1,0.2,2,1,2,1\\r\\n54,0,2,160,201,0,1,163,0,0,2,1,2,1\\r\\n49,0,1,134,271,0,1,162,0,0,1,0,2,1\\r\\n42,1,1,120,295,0,1,162,0,0,2,0,2,1\\r\\n41,1,1,110,235,0,1,153,0,0,2,0,2,1\\r\\n41,0,1,126,306,0,1,163,0,0,2,0,2,1\\r\\n49,0,0,130,269,0,1,163,0,0,2,0,2,1\\r\\n60,0,2,120,178,1,1,96,0,0,2,0,2,1\\r\\n62,1,1,128,208,1,0,140,0,0,2,0,2,1\\r\\n57,1,0,110,201,0,1,126,1,1.5,1,0,1,1\\r\\n64,1,0,128,263,0,1,105,1,0.2,1,1,3,1\\r\\n51,0,2,120,295,0,0,157,0,0.6,2,0,2,1\\r\\n43,1,0,115,303,0,1,181,0,1.2,1,0,2,1\\r\\n42,0,2,120,209,0,1,173,0,0,1,0,2,1\\r\\n67,0,0,106,223,0,1,142,0,0.3,2,2,2,1\\r\\n76,0,2,140,197,0,2,116,0,1.1,1,0,2,1\\r\\n70,1,1,156,245,0,0,143,0,0,2,0,2,1\\r\\n44,0,2,118,242,0,1,149,0,0.3,1,1,2,1\\r\\n60,0,3,150,240,0,1,171,0,0.9,2,0,2,1\\r\\n44,1,2,120,226,0,1,169,0,0,2,0,2,1\\r\\n42,1,2,130,180,0,1,150,0,0,2,0,2,1\\r\\n66,1,0,160,228,0,0,138,0,2.3,2,0,1,1\\r\\n71,0,0,112,149,0,1,125,0,1.6,1,0,2,1\\r\\n64,1,3,170,227,0,0,155,0,0.6,1,0,3,1\\r\\n66,0,2,146,278,0,0,152,0,0,1,1,2,1\\r\\n39,0,2,138,220,0,1,152,0,0,1,0,2,1\\r\\n58,0,0,130,197,0,1,131,0,0.6,1,0,2,1\\r\\n47,1,2,130,253,0,1,179,0,0,2,0,2,1\\r\\n35,1,1,122,192,0,1,174,0,0,2,0,2,1\\r\\n58,1,1,125,220,0,1,144,0,0.4,1,4,3,1\\r\\n56,1,1,130,221,0,0,163,0,0,2,0,3,1\\r\\n56,1,1,120,240,0,1,169,0,0,0,0,2,1\\r\\n55,0,1,132,342,0,1,166,0,1.2,2,0,2,1\\r\\n41,1,1,120,157,0,1,182,0,0,2,0,2,1\\r\\n38,1,2,138,175,0,1,173,0,0,2,4,2,1\\r\\n38,1,2,138,175,0,1,173,0,0,2,4,2,1\\r\\n67,1,0,160,286,0,0,108,1,1.5,1,3,2,0\\r\\n67,1,0,120,229,0,0,129,1,2.6,1,2,3,0\\r\\n62,0,0,140,268,0,0,160,0,3.6,0,2,2,0\\r\\n63,1,0,130,254,0,0,147,0,1.4,1,1,3,0\\r\\n53,1,0,140,203,1,0,155,1,3.1,0,0,3,0\\r\\n56,1,2,130,256,1,0,142,1,0.6,1,1,1,0\\r\\n48,1,1,110,229,0,1,168,0,1,0,0,3,0\\r\\n58,1,1,120,284,0,0,160,0,1.8,1,0,2,0\\r\\n58,1,2,132,224,0,0,173,0,3.2,2,2,3,0\\r\\n60,1,0,130,206,0,0,132,1,2.4,1,2,3,0\\r\\n40,1,0,110,167,0,0,114,1,2,1,0,3,0\\r\\n60,1,0,117,230,1,1,160,1,1.4,2,2,3,0\\r\\n64,1,2,140,335,0,1,158,0,0,2,0,2,0\\r\\n43,1,0,120,177,0,0,120,1,2.5,1,0,3,0\\r\\n57,1,0,150,276,0,0,112,1,0.6,1,1,1,0\\r\\n55,1,0,132,353,0,1,132,1,1.2,1,1,3,0\\r\\n65,0,0,150,225,0,0,114,0,1,1,3,3,0\\r\\n61,0,0,130,330,0,0,169,0,0,2,0,2,0\\r\\n58,1,2,112,230,0,0,165,0,2.5,1,1,3,0\\r\\n50,1,0,150,243,0,0,128,0,2.6,1,0,3,0\\r\\n44,1,0,112,290,0,0,153,0,0,2,1,2,0\\r\\n60,1,0,130,253,0,1,144,1,1.4,2,1,3,0\\r\\n54,1,0,124,266,0,0,109,1,2.2,1,1,3,0\\r\\n50,1,2,140,233,0,1,163,0,0.6,1,1,3,0\\r\\n41,1,0,110,172,0,0,158,0,0,2,0,3,0\\r\\n51,0,0,130,305,0,1,142,1,1.2,1,0,3,0\\r\\n58,1,0,128,216,0,0,131,1,2.2,1,3,3,0\\r\\n54,1,0,120,188,0,1,113,0,1.4,1,1,3,0\\r\\n60,1,0,145,282,0,0,142,1,2.8,1,2,3,0\\r\\n60,1,2,140,185,0,0,155,0,3,1,0,2,0\\r\\n59,1,0,170,326,0,0,140,1,3.4,0,0,3,0\\r\\n46,1,2,150,231,0,1,147,0,3.6,1,0,2,0\\r\\n67,1,0,125,254,1,1,163,0,0.2,1,2,3,0\\r\\n62,1,0,120,267,0,1,99,1,1.8,1,2,3,0\\r\\n65,1,0,110,248,0,0,158,0,0.6,2,2,1,0\\r\\n44,1,0,110,197,0,0,177,0,0,2,1,2,0\\r\\n60,1,0,125,258,0,0,141,1,2.8,1,1,3,0\\r\\n58,1,0,150,270,0,0,111,1,0.8,2,0,3,0\\r\\n68,1,2,180,274,1,0,150,1,1.6,1,0,3,0\\r\\n62,0,0,160,164,0,0,145,0,6.2,0,3,3,0\\r\\n52,1,0,128,255,0,1,161,1,0,2,1,3,0\\r\\n59,1,0,110,239,0,0,142,1,1.2,1,1,3,0\\r\\n60,0,0,150,258,0,0,157,0,2.6,1,2,3,0\\r\\n49,1,2,120,188,0,1,139,0,2,1,3,3,0\\r\\n59,1,0,140,177,0,1,162,1,0,2,1,3,0\\r\\n57,1,2,128,229,0,0,150,0,0.4,1,1,3,0\\r\\n61,1,0,120,260,0,1,140,1,3.6,1,1,3,0\\r\\n39,1,0,118,219,0,1,140,0,1.2,1,0,3,0\\r\\n61,0,0,145,307,0,0,146,1,1,1,0,3,0\\r\\n56,1,0,125,249,1,0,144,1,1.2,1,1,2,0\\r\\n43,0,0,132,341,1,0,136,1,3,1,0,3,0\\r\\n62,0,2,130,263,0,1,97,0,1.2,1,1,3,0\\r\\n63,1,0,130,330,1,0,132,1,1.8,2,3,3,0\\r\\n65,1,0,135,254,0,0,127,0,2.8,1,1,3,0\\r\\n48,1,0,130,256,1,0,150,1,0,2,2,3,0\\r\\n63,0,0,150,407,0,0,154,0,4,1,3,3,0\\r\\n55,1,0,140,217,0,1,111,1,5.6,0,0,3,0\\r\\n65,1,3,138,282,1,0,174,0,1.4,1,1,2,0\\r\\n56,0,0,200,288,1,0,133,1,4,0,2,3,0\\r\\n54,1,0,110,239,0,1,126,1,2.8,1,1,3,0\\r\\n70,1,0,145,174,0,1,125,1,2.6,0,0,3,0\\r\\n62,1,1,120,281,0,0,103,0,1.4,1,1,3,0\\r\\n35,1,0,120,198,0,1,130,1,1.6,1,0,3,0\\r\\n59,1,3,170,288,0,0,159,0,0.2,1,0,3,0\\r\\n64,1,2,125,309,0,1,131,1,1.8,1,0,3,0\\r\\n47,1,2,108,243,0,1,152,0,0,2,0,2,0\\r\\n57,1,0,165,289,1,0,124,0,1,1,3,3,0\\r\\n55,1,0,160,289,0,0,145,1,0.8,1,1,3,0\\r\\n64,1,0,120,246,0,0,96,1,2.2,0,1,2,0\\r\\n70,1,0,130,322,0,0,109,0,2.4,1,3,2,0\\r\\n51,1,0,140,299,0,1,173,1,1.6,2,0,3,0\\r\\n58,1,0,125,300,0,0,171,0,0,2,2,3,0\\r\\n60,1,0,140,293,0,0,170,0,1.2,1,2,3,0\\r\\n77,1,0,125,304,0,0,162,1,0,2,3,2,0\\r\\n35,1,0,126,282,0,0,156,1,0,2,0,3,0\\r\\n70,1,2,160,269,0,1,112,1,2.9,1,1,3,0\\r\\n59,0,0,174,249,0,1,143,1,0,1,0,2,0\\r\\n64,1,0,145,212,0,0,132,0,2,1,2,1,0\\r\\n57,1,0,152,274,0,1,88,1,1.2,1,1,3,0\\r\\n56,1,0,132,184,0,0,105,1,2.1,1,1,1,0\\r\\n48,1,0,124,274,0,0,166,0,0.5,1,0,3,0\\r\\n56,0,0,134,409,0,0,150,1,1.9,1,2,3,0\\r\\n66,1,1,160,246,0,1,120,1,0,1,3,1,0\\r\\n54,1,1,192,283,0,0,195,0,0,2,1,3,0\\r\\n69,1,2,140,254,0,0,146,0,2,1,3,3,0\\r\\n51,1,0,140,298,0,1,122,1,4.2,1,3,3,0\\r\\n43,1,0,132,247,1,0,143,1,0.1,1,4,3,0\\r\\n62,0,0,138,294,1,1,106,0,1.9,1,3,2,0\\r\\n67,1,0,100,299,0,0,125,1,0.9,1,2,2,0\\r\\n59,1,3,160,273,0,0,125,0,0,2,0,2,0\\r\\n45,1,0,142,309,0,0,147,1,0,1,3,3,0\\r\\n58,1,0,128,259,0,0,130,1,3,1,2,3,0\\r\\n50,1,0,144,200,0,0,126,1,0.9,1,0,3,0\\r\\n62,0,0,150,244,0,1,154,1,1.4,1,0,2,0\\r\\n38,1,3,120,231,0,1,182,1,3.8,1,0,3,0\\r\\n66,0,0,178,228,1,1,165,1,1,1,2,3,0\\r\\n52,1,0,112,230,0,1,160,0,0,2,1,2,0\\r\\n53,1,0,123,282,0,1,95,1,2,1,2,3,0\\r\\n63,0,0,108,269,0,1,169,1,1.8,1,2,2,0\\r\\n54,1,0,110,206,0,0,108,1,0,1,1,2,0\\r\\n66,1,0,112,212,0,0,132,1,0.1,2,1,2,0\\r\\n55,0,0,180,327,0,2,117,1,3.4,1,0,2,0\\r\\n49,1,2,118,149,0,0,126,0,0.8,2,3,2,0\\r\\n54,1,0,122,286,0,0,116,1,3.2,1,2,2,0\\r\\n56,1,0,130,283,1,0,103,1,1.6,0,0,3,0\\r\\n46,1,0,120,249,0,0,144,0,0.8,2,0,3,0\\r\\n61,1,3,134,234,0,1,145,0,2.6,1,2,2,0\\r\\n67,1,0,120,237,0,1,71,0,1,1,0,2,0\\r\\n58,1,0,100,234,0,1,156,0,0.1,2,1,3,0\\r\\n47,1,0,110,275,0,0,118,1,1,1,1,2,0\\r\\n52,1,0,125,212,0,1,168,0,1,2,2,3,0\\r\\n58,1,0,146,218,0,1,105,0,2,1,1,3,0\\r\\n57,1,1,124,261,0,1,141,0,0.3,2,0,3,0\\r\\n58,0,1,136,319,1,0,152,0,0,2,2,2,0\\r\\n61,1,0,138,166,0,0,125,1,3.6,1,1,2,0\\r\\n42,1,0,136,315,0,1,125,1,1.8,1,0,1,0\\r\\n52,1,0,128,204,1,1,156,1,1,1,0,0,0\\r\\n59,1,2,126,218,1,1,134,0,2.2,1,1,1,0\\r\\n40,1,0,152,223,0,1,181,0,0,2,0,3,0\\r\\n61,1,0,140,207,0,0,138,1,1.9,2,1,3,0\\r\\n46,1,0,140,311,0,1,120,1,1.8,1,2,3,0\\r\\n59,1,3,134,204,0,1,162,0,0.8,2,2,2,0\\r\\n57,1,1,154,232,0,0,164,0,0,2,1,2,0\\r\\n57,1,0,110,335,0,1,143,1,3,1,1,3,0\\r\\n55,0,0,128,205,0,2,130,1,2,1,1,3,0\\r\\n61,1,0,148,203,0,1,161,0,0,2,1,3,0\\r\\n58,1,0,114,318,0,2,140,0,4.4,0,3,1,0\\r\\n58,0,0,170,225,1,0,146,1,2.8,1,2,1,0\\r\\n67,1,2,152,212,0,0,150,0,0.8,1,0,3,0\\r\\n44,1,0,120,169,0,1,144,1,2.8,0,0,1,0\\r\\n63,1,0,140,187,0,0,144,1,4,2,2,3,0\\r\\n63,0,0,124,197,0,1,136,1,0,1,0,2,0\\r\\n59,1,0,164,176,1,0,90,0,1,1,2,1,0\\r\\n57,0,0,140,241,0,1,123,1,0.2,1,0,3,0\\r\\n45,1,3,110,264,0,1,132,0,1.2,1,0,3,0\\r\\n68,1,0,144,193,1,1,141,0,3.4,1,2,3,0\\r\\n57,1,0,130,131,0,1,115,1,1.2,1,1,3,0\\r\\n57,0,1,130,236,0,0,174,0,0,1,1,2,0\\r\\n'}"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#read data\n",
        "\n",
        "data = pd.read_csv(\"heart.csv\")\n",
        "data.head"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-EdlI__noiA",
        "outputId": "a94cb812-a662-4fa2-a65d-e0e17dc8b65f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method NDFrame.head of      age  sex  cp  trestbps  chol  fbs  ...  exang  oldpeak  slope  ca  thal  target\n",
              "0     63    1   3       145   233    1  ...      0      2.3      0   0     1       1\n",
              "1     37    1   2       130   250    0  ...      0      3.5      0   0     2       1\n",
              "2     41    0   1       130   204    0  ...      0      1.4      2   0     2       1\n",
              "3     56    1   1       120   236    0  ...      0      0.8      2   0     2       1\n",
              "4     57    0   0       120   354    0  ...      1      0.6      2   0     2       1\n",
              "..   ...  ...  ..       ...   ...  ...  ...    ...      ...    ...  ..   ...     ...\n",
              "298   57    0   0       140   241    0  ...      1      0.2      1   0     3       0\n",
              "299   45    1   3       110   264    0  ...      0      1.2      1   0     3       0\n",
              "300   68    1   0       144   193    1  ...      0      3.4      1   2     3       0\n",
              "301   57    1   0       130   131    0  ...      1      1.2      1   1     3       0\n",
              "302   57    0   1       130   236    0  ...      0      0.0      1   1     2       0\n",
              "\n",
              "[303 rows x 14 columns]>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Check missing data"
      ],
      "metadata": {
        "id": "G_A8WA6n5oS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "data.isna().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MAZfMzNooY9S",
        "outputId": "07894140-27ee-4a1c-ada2-9acd3e96101d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "age         0\n",
              "sex         0\n",
              "cp          0\n",
              "trestbps    0\n",
              "chol        0\n",
              "fbs         0\n",
              "restecg     0\n",
              "thalach     0\n",
              "exang       0\n",
              "oldpeak     0\n",
              "slope       0\n",
              "ca          0\n",
              "thal        0\n",
              "target      0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Split data\n"
      ],
      "metadata": {
        "id": "237trTBv5mlJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = data.drop('target', axis=1)\n",
        "y = data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=0)"
      ],
      "metadata": {
        "id": "bN7JvUW9q2Ca"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Normalize data"
      ],
      "metadata": {
        "id": "X7i5Y2p457rt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Scaling train data\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "sc = StandardScaler()\n",
        "col_to_scale = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']\n",
        "X_train[col_to_scale] = sc.fit_transform(X_train[col_to_scale])"
      ],
      "metadata": {
        "id": "BXDFZWWxpBN4"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "hGuaaN5CpPRA",
        "outputId": "3079154d-ee88-49ab-d0c2-7bb64a56c236"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-fd4121cf-ae4f-4e93-bdaf-4af85943f3bc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>cp</th>\n",
              "      <th>trestbps</th>\n",
              "      <th>chol</th>\n",
              "      <th>fbs</th>\n",
              "      <th>restecg</th>\n",
              "      <th>thalach</th>\n",
              "      <th>exang</th>\n",
              "      <th>oldpeak</th>\n",
              "      <th>slope</th>\n",
              "      <th>ca</th>\n",
              "      <th>thal</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>74</th>\n",
              "      <td>-1.327733</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>-0.574125</td>\n",
              "      <td>-0.632674</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.656262</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.724609</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153</th>\n",
              "      <td>1.249032</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.831066</td>\n",
              "      <td>0.585437</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.094007</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.892493</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>0.352766</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0.479768</td>\n",
              "      <td>-0.670155</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.656262</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.892493</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>296</th>\n",
              "      <td>0.912932</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.457026</td>\n",
              "      <td>-0.932517</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.597999</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.892493</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>287</th>\n",
              "      <td>0.240733</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.299463</td>\n",
              "      <td>-0.276611</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.613011</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.892493</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>251</th>\n",
              "      <td>-1.327733</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.011371</td>\n",
              "      <td>0.004491</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.295246</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.808551</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>192</th>\n",
              "      <td>-0.095367</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.691224</td>\n",
              "      <td>-1.101178</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>-1.592757</td>\n",
              "      <td>0</td>\n",
              "      <td>0.282698</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>117</th>\n",
              "      <td>0.128699</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>-0.691224</td>\n",
              "      <td>-1.007478</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.526511</td>\n",
              "      <td>0</td>\n",
              "      <td>0.702409</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>-0.879600</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0.362669</td>\n",
              "      <td>0.191893</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.267008</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.892493</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>172</th>\n",
              "      <td>0.352766</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.691224</td>\n",
              "      <td>0.697878</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.440010</td>\n",
              "      <td>0</td>\n",
              "      <td>0.618467</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>242 rows × 13 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fd4121cf-ae4f-4e93-bdaf-4af85943f3bc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fd4121cf-ae4f-4e93-bdaf-4af85943f3bc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fd4121cf-ae4f-4e93-bdaf-4af85943f3bc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "          age  sex  cp  trestbps      chol  ...  exang   oldpeak  slope  ca  thal\n",
              "74  -1.327733    0   2 -0.574125 -0.632674  ...      0 -0.724609      1   0     2\n",
              "153  1.249032    0   2  0.831066  0.585437  ...      0 -0.892493      1   1     2\n",
              "64   0.352766    1   2  0.479768 -0.670155  ...      0 -0.892493      2   0     2\n",
              "296  0.912932    0   0 -0.457026 -0.932517  ...      1 -0.892493      1   0     2\n",
              "287  0.240733    1   1  1.299463 -0.276611  ...      0 -0.892493      2   1     2\n",
              "..        ...  ...  ..       ...       ...  ...    ...       ...    ...  ..   ...\n",
              "251 -1.327733    1   0  0.011371  0.004491  ...      1 -0.808551      1   4     3\n",
              "192 -0.095367    1   0 -0.691224 -1.101178  ...      0  0.282698      1   1     3\n",
              "117  0.128699    1   3 -0.691224 -1.007478  ...      0  0.702409      1   0     3\n",
              "47  -0.879600    1   2  0.362669  0.191893  ...      0 -0.892493      2   0     2\n",
              "172  0.352766    1   1 -0.691224  0.697878  ...      0  0.618467      1   0     2\n",
              "\n",
              "[242 rows x 13 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Scaling test data\n",
        "X_test[col_to_scale] = sc.transform(X_test[col_to_scale])"
      ],
      "metadata": {
        "id": "wVHVtGsKskkx"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "fx0pxrRTs1s3",
        "outputId": "f3d0464c-4a09-49c5-8aba-602de94c19c8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-9e336e13-2f7e-41c5-b498-0396f2d3385e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>cp</th>\n",
              "      <th>trestbps</th>\n",
              "      <th>chol</th>\n",
              "      <th>fbs</th>\n",
              "      <th>restecg</th>\n",
              "      <th>thalach</th>\n",
              "      <th>exang</th>\n",
              "      <th>oldpeak</th>\n",
              "      <th>slope</th>\n",
              "      <th>ca</th>\n",
              "      <th>thal</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>225</th>\n",
              "      <td>1.697165</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.772516</td>\n",
              "      <td>-1.363541</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>-1.073753</td>\n",
              "      <td>1</td>\n",
              "      <td>1.290005</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>152</th>\n",
              "      <td>1.024965</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2.236257</td>\n",
              "      <td>-0.370312</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.223758</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.388840</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>228</th>\n",
              "      <td>0.464799</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2.236257</td>\n",
              "      <td>0.772838</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.396759</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.724609</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>201</th>\n",
              "      <td>0.576832</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.398476</td>\n",
              "      <td>0.210633</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.381747</td>\n",
              "      <td>1</td>\n",
              "      <td>1.457889</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>0.800899</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>-0.105728</td>\n",
              "      <td>-0.295351</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.165495</td>\n",
              "      <td>0</td>\n",
              "      <td>0.618467</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>-1.215700</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>-0.808324</td>\n",
              "      <td>-0.089209</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.035744</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.640667</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>302</th>\n",
              "      <td>0.240733</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.105728</td>\n",
              "      <td>-0.201650</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.045515</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.892493</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>0.464799</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1.065265</td>\n",
              "      <td>-0.651414</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.310259</td>\n",
              "      <td>0</td>\n",
              "      <td>0.450583</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108</th>\n",
              "      <td>-0.543500</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.691224</td>\n",
              "      <td>-0.051729</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.526511</td>\n",
              "      <td>0</td>\n",
              "      <td>0.030871</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89</th>\n",
              "      <td>0.352766</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-1.862217</td>\n",
              "      <td>0.023232</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-1.203504</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.053071</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>61 rows × 13 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9e336e13-2f7e-41c5-b498-0396f2d3385e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9e336e13-2f7e-41c5-b498-0396f2d3385e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9e336e13-2f7e-41c5-b498-0396f2d3385e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "          age  sex  cp  trestbps      chol  ...  exang   oldpeak  slope  ca  thal\n",
              "225  1.697165    1   0  0.772516 -1.363541  ...      1  1.290005      0   0     3\n",
              "152  1.024965    1   3  2.236257 -0.370312  ...      0 -0.388840      1   0     3\n",
              "228  0.464799    1   3  2.236257  0.772838  ...      0 -0.724609      1   0     3\n",
              "201  0.576832    1   0 -0.398476  0.210633  ...      1  1.457889      1   1     3\n",
              "52   0.800899    1   2 -0.105728 -0.295351  ...      0  0.618467      1   3     3\n",
              "..        ...  ...  ..       ...       ...  ...    ...       ...    ...  ..   ...\n",
              "146 -1.215700    0   2 -0.808324 -0.089209  ...      0 -0.640667      1   1     2\n",
              "302  0.240733    0   1 -0.105728 -0.201650  ...      0 -0.892493      1   1     2\n",
              "26   0.464799    1   2  1.065265 -0.651414  ...      0  0.450583      2   0     2\n",
              "108 -0.543500    0   1 -0.691224 -0.051729  ...      0  0.030871      2   0     2\n",
              "89   0.352766    0   0 -1.862217  0.023232  ...      0 -0.053071      1   0     2\n",
              "\n",
              "[61 rows x 13 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **TRAIN MODEL**"
      ],
      "metadata": {
        "id": "5kVI-_QL6IVG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##*create print result funtion*"
      ],
      "metadata": {
        "id": "Sx-P-sDe74ud"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "def print_result(model,pred, X_train, y_train, X_test, y_test):     \n",
        "        model_report = pd.DataFrame(classification_report(y_test, pred, output_dict=True))\n",
        "        print(\"Train Result:\\n================================================\")        \n",
        "        print(f\"Accuracy Score: {accuracy_score(y_test, pred) * 100:.2f}%\")\n",
        "        print(\"_______________________________________________\")\n",
        "        print(f\"CLASSIFICATION REPORT:\\n{model_report}\")\n",
        "        print(\"_______________________________________________\")\n",
        "        print(f\"Confusion Matrix: \\n {confusion_matrix(y_test, pred)}\\n\")\n",
        "        "
      ],
      "metadata": {
        "id": "zdkAgbiK3ofT"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Logistic Regression**"
      ],
      "metadata": {
        "id": "OU8MorWQ8F9N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "lr_model = LogisticRegression(solver='liblinear')\n",
        "lr_model.fit(X_train, y_train)\n",
        "lr_pred = lr_model.predict(X_test)\n",
        "print_result(lr_model,lr_pred, X_train, y_train, X_test, y_test)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jSxrsMVuv5iw",
        "outputId": "5c01e094-1812-4780-cdae-76765aeae34e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Result:\n",
            "================================================\n",
            "Accuracy Score: 85.25%\n",
            "_______________________________________________\n",
            "CLASSIFICATION REPORT:\n",
            "                   0          1  accuracy  macro avg  weighted avg\n",
            "precision   0.875000   0.837838  0.852459   0.856419      0.854287\n",
            "recall      0.777778   0.911765  0.852459   0.844771      0.852459\n",
            "f1-score    0.823529   0.873239  0.852459   0.848384      0.851237\n",
            "support    27.000000  34.000000  0.852459  61.000000     61.000000\n",
            "_______________________________________________\n",
            "Confusion Matrix: \n",
            " [[21  6]\n",
            " [ 3 31]]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###R*esult with new input*"
      ],
      "metadata": {
        "id": "emyPcMe08TcW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Result with new input\n",
        "new_input = [37,\t1,\t2,\t130,\t250,\t0,\t1,\t187,\t0,\t3.5,\t0,\t0,\t2\t]\n",
        "lr_model.predict([new_input])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wn2Lxb1QpVq-",
        "outputId": "3027cc36-0a38-4fc5-ad2c-d7e0dfce6f18"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Support Vector machine**"
      ],
      "metadata": {
        "id": "fwrcznA58c9N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "\n",
        "svm_model = SVC(kernel='rbf', gamma=0.1, C=1.0)\n",
        "svm_model.fit(X_train, y_train)\n",
        "svm_pred = svm_model.predict(X_test)\n",
        "\n",
        "print_result(svm_model,svm_pred, X_train, y_train, X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iFxNa0bS4FCS",
        "outputId": "83fbcf93-ef79-4422-bd0c-e0b062ae6507"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Result:\n",
            "================================================\n",
            "Accuracy Score: 85.25%\n",
            "_______________________________________________\n",
            "CLASSIFICATION REPORT:\n",
            "                   0          1  accuracy  macro avg  weighted avg\n",
            "precision   0.909091   0.820513  0.852459   0.864802      0.859720\n",
            "recall      0.740741   0.941176  0.852459   0.840959      0.852459\n",
            "f1-score    0.816327   0.876712  0.852459   0.846519      0.849984\n",
            "support    27.000000  34.000000  0.852459  61.000000     61.000000\n",
            "_______________________________________________\n",
            "Confusion Matrix: \n",
            " [[20  7]\n",
            " [ 2 32]]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Result with new input\n",
        "new_input = [37,\t1,\t2,\t130,\t250,\t0,\t1,\t187,\t0,\t3.5,\t0,\t0,\t2\t]\n",
        "svm_model.predict([new_input])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sP07OilT-UyH",
        "outputId": "38d5031b-c6ba-4361-b8df-b761b3c7c053"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "\n",
        "tree_model = DecisionTreeClassifier(random_state=42)\n",
        "tree_model.fit(X_train, y_train)\n",
        "tree_pred = tree_model.predict(X_test)\n",
        "\n",
        "print_result(tree_model,tree_pred, X_train, y_train, X_test, y_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WiDoFgcs4Hw8",
        "outputId": "f5f62775-cb5d-4797-aac3-28e9a4a91e2e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Result:\n",
            "================================================\n",
            "Accuracy Score: 77.05%\n",
            "_______________________________________________\n",
            "CLASSIFICATION REPORT:\n",
            "                   0          1  accuracy  macro avg  weighted avg\n",
            "precision   0.709677   0.833333  0.770492   0.771505      0.778600\n",
            "recall      0.814815   0.735294  0.770492   0.775054      0.770492\n",
            "f1-score    0.758621   0.781250  0.770492   0.769935      0.771234\n",
            "support    27.000000  34.000000  0.770492  61.000000     61.000000\n",
            "_______________________________________________\n",
            "Confusion Matrix: \n",
            " [[22  5]\n",
            " [ 9 25]]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Result with new input\n",
        "new_input = [37,\t1,\t2,\t130,\t250,\t0,\t1,\t187,\t0,\t3.5,\t0,\t0,\t2\t]\n",
        "tree_model.predict([new_input])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fsPe1E1E-bxW",
        "outputId": "f05a5b80-bfd7-490d-f506-6d581e1560c6"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Random Forest**"
      ],
      "metadata": {
        "id": "Oj89Lhx49AEf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "rf_model = RandomForestClassifier(n_estimators=1000, random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "rf_pred = rf_model.predict(X_test)\n",
        "\n",
        "print_result(rf_model,rf_pred, X_train, y_train, X_test, y_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LI0UIQf34KE4",
        "outputId": "bb79a8fd-a896-41a3-b5d8-74a04b51d74e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Result:\n",
            "================================================\n",
            "Accuracy Score: 85.25%\n",
            "_______________________________________________\n",
            "CLASSIFICATION REPORT:\n",
            "                   0          1  accuracy  macro avg  weighted avg\n",
            "precision   0.846154   0.857143  0.852459   0.851648      0.852279\n",
            "recall      0.814815   0.882353  0.852459   0.848584      0.852459\n",
            "f1-score    0.830189   0.869565  0.852459   0.849877      0.852136\n",
            "support    27.000000  34.000000  0.852459  61.000000     61.000000\n",
            "_______________________________________________\n",
            "Confusion Matrix: \n",
            " [[22  5]\n",
            " [ 4 30]]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Result with new input\n",
        "new_input = [37,\t1,\t2,\t130,\t250,\t0,\t1,\t187,\t0,\t3.5,\t0,\t0,\t2\t]\n",
        "rf_model.predict([new_input])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a45VyL6f-prd",
        "outputId": "aabb9a98-d0a5-49db-ce13-922731231c06"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **XGBoost Classifer**"
      ],
      "metadata": {
        "id": "fWCEHNZW9MVV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "\n",
        "xgb_model = XGBClassifier(use_label_encoder=False)\n",
        "xgb_model.fit(X_train, y_train)\n",
        "xgb_model.fit(X_train, y_train)\n",
        "xgb_pred = xgb_model.predict(X_test)\n",
        "\n",
        "print_result(xgb_model,xgb_pred, X_train, y_train, X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gPietzkI2km5",
        "outputId": "d6e1108a-1516-4126-b1e1-e8cdecfa602f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Result:\n",
            "================================================\n",
            "Accuracy Score: 85.25%\n",
            "_______________________________________________\n",
            "CLASSIFICATION REPORT:\n",
            "                   0          1  accuracy  macro avg  weighted avg\n",
            "precision   0.846154   0.857143  0.852459   0.851648      0.852279\n",
            "recall      0.814815   0.882353  0.852459   0.848584      0.852459\n",
            "f1-score    0.830189   0.869565  0.852459   0.849877      0.852136\n",
            "support    27.000000  34.000000  0.852459  61.000000     61.000000\n",
            "_______________________________________________\n",
            "Confusion Matrix: \n",
            " [[22  5]\n",
            " [ 4 30]]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Neural network**"
      ],
      "metadata": {
        "id": "q783YPg19VUp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "y_train_nn = to_categorical(y_train)"
      ],
      "metadata": {
        "id": "LpHChfJh5WE_"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import models"
      ],
      "metadata": {
        "id": "2E9YEahszjFE"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# FFNN with relu\n",
        "nn_model = models.Sequential()\n",
        "nn_model.add(layers.Dense(15, activation='relu'))\n",
        "nn_model.add(layers.Dense(10,activation='relu'))\n",
        "\n",
        "nn_model.add(layers.Dense(2,activation='softmax'))\n",
        "\n",
        "\n",
        "nn_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "izLk3lIN5wli"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nn_model.fit(X_train,y_train_nn,epochs=100, batch_size=30, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJT5O_Iz5zft",
        "outputId": "80b12614-3dee-486f-aece-3d64cbf2cc11"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "9/9 - 1s - loss: 0.7533 - accuracy: 0.5413 - 748ms/epoch - 83ms/step\n",
            "Epoch 2/100\n",
            "9/9 - 0s - loss: 0.7257 - accuracy: 0.5413 - 19ms/epoch - 2ms/step\n",
            "Epoch 3/100\n",
            "9/9 - 0s - loss: 0.7061 - accuracy: 0.5413 - 18ms/epoch - 2ms/step\n",
            "Epoch 4/100\n",
            "9/9 - 0s - loss: 0.6893 - accuracy: 0.5496 - 20ms/epoch - 2ms/step\n",
            "Epoch 5/100\n",
            "9/9 - 0s - loss: 0.6765 - accuracy: 0.5413 - 20ms/epoch - 2ms/step\n",
            "Epoch 6/100\n",
            "9/9 - 0s - loss: 0.6628 - accuracy: 0.5785 - 17ms/epoch - 2ms/step\n",
            "Epoch 7/100\n",
            "9/9 - 0s - loss: 0.6506 - accuracy: 0.6074 - 17ms/epoch - 2ms/step\n",
            "Epoch 8/100\n",
            "9/9 - 0s - loss: 0.6397 - accuracy: 0.6281 - 34ms/epoch - 4ms/step\n",
            "Epoch 9/100\n",
            "9/9 - 0s - loss: 0.6263 - accuracy: 0.6570 - 23ms/epoch - 3ms/step\n",
            "Epoch 10/100\n",
            "9/9 - 0s - loss: 0.6144 - accuracy: 0.6736 - 19ms/epoch - 2ms/step\n",
            "Epoch 11/100\n",
            "9/9 - 0s - loss: 0.6020 - accuracy: 0.7107 - 28ms/epoch - 3ms/step\n",
            "Epoch 12/100\n",
            "9/9 - 0s - loss: 0.5891 - accuracy: 0.7355 - 31ms/epoch - 3ms/step\n",
            "Epoch 13/100\n",
            "9/9 - 0s - loss: 0.5775 - accuracy: 0.7562 - 17ms/epoch - 2ms/step\n",
            "Epoch 14/100\n",
            "9/9 - 0s - loss: 0.5661 - accuracy: 0.7851 - 23ms/epoch - 3ms/step\n",
            "Epoch 15/100\n",
            "9/9 - 0s - loss: 0.5546 - accuracy: 0.7934 - 25ms/epoch - 3ms/step\n",
            "Epoch 16/100\n",
            "9/9 - 0s - loss: 0.5438 - accuracy: 0.8058 - 16ms/epoch - 2ms/step\n",
            "Epoch 17/100\n",
            "9/9 - 0s - loss: 0.5329 - accuracy: 0.8182 - 19ms/epoch - 2ms/step\n",
            "Epoch 18/100\n",
            "9/9 - 0s - loss: 0.5218 - accuracy: 0.8099 - 22ms/epoch - 2ms/step\n",
            "Epoch 19/100\n",
            "9/9 - 0s - loss: 0.5102 - accuracy: 0.8058 - 32ms/epoch - 4ms/step\n",
            "Epoch 20/100\n",
            "9/9 - 0s - loss: 0.4984 - accuracy: 0.8099 - 29ms/epoch - 3ms/step\n",
            "Epoch 21/100\n",
            "9/9 - 0s - loss: 0.4876 - accuracy: 0.8058 - 23ms/epoch - 3ms/step\n",
            "Epoch 22/100\n",
            "9/9 - 0s - loss: 0.4757 - accuracy: 0.8058 - 26ms/epoch - 3ms/step\n",
            "Epoch 23/100\n",
            "9/9 - 0s - loss: 0.4676 - accuracy: 0.8182 - 26ms/epoch - 3ms/step\n",
            "Epoch 24/100\n",
            "9/9 - 0s - loss: 0.4572 - accuracy: 0.8140 - 30ms/epoch - 3ms/step\n",
            "Epoch 25/100\n",
            "9/9 - 0s - loss: 0.4476 - accuracy: 0.8099 - 26ms/epoch - 3ms/step\n",
            "Epoch 26/100\n",
            "9/9 - 0s - loss: 0.4405 - accuracy: 0.8140 - 32ms/epoch - 4ms/step\n",
            "Epoch 27/100\n",
            "9/9 - 0s - loss: 0.4333 - accuracy: 0.8099 - 29ms/epoch - 3ms/step\n",
            "Epoch 28/100\n",
            "9/9 - 0s - loss: 0.4280 - accuracy: 0.8140 - 36ms/epoch - 4ms/step\n",
            "Epoch 29/100\n",
            "9/9 - 0s - loss: 0.4231 - accuracy: 0.8140 - 17ms/epoch - 2ms/step\n",
            "Epoch 30/100\n",
            "9/9 - 0s - loss: 0.4187 - accuracy: 0.8182 - 32ms/epoch - 4ms/step\n",
            "Epoch 31/100\n",
            "9/9 - 0s - loss: 0.4145 - accuracy: 0.8223 - 26ms/epoch - 3ms/step\n",
            "Epoch 32/100\n",
            "9/9 - 0s - loss: 0.4121 - accuracy: 0.8223 - 26ms/epoch - 3ms/step\n",
            "Epoch 33/100\n",
            "9/9 - 0s - loss: 0.4070 - accuracy: 0.8264 - 21ms/epoch - 2ms/step\n",
            "Epoch 34/100\n",
            "9/9 - 0s - loss: 0.4046 - accuracy: 0.8306 - 27ms/epoch - 3ms/step\n",
            "Epoch 35/100\n",
            "9/9 - 0s - loss: 0.4032 - accuracy: 0.8140 - 28ms/epoch - 3ms/step\n",
            "Epoch 36/100\n",
            "9/9 - 0s - loss: 0.4020 - accuracy: 0.8182 - 25ms/epoch - 3ms/step\n",
            "Epoch 37/100\n",
            "9/9 - 0s - loss: 0.3975 - accuracy: 0.8223 - 16ms/epoch - 2ms/step\n",
            "Epoch 38/100\n",
            "9/9 - 0s - loss: 0.3950 - accuracy: 0.8223 - 24ms/epoch - 3ms/step\n",
            "Epoch 39/100\n",
            "9/9 - 0s - loss: 0.3926 - accuracy: 0.8223 - 37ms/epoch - 4ms/step\n",
            "Epoch 40/100\n",
            "9/9 - 0s - loss: 0.3914 - accuracy: 0.8388 - 25ms/epoch - 3ms/step\n",
            "Epoch 41/100\n",
            "9/9 - 0s - loss: 0.3900 - accuracy: 0.8430 - 27ms/epoch - 3ms/step\n",
            "Epoch 42/100\n",
            "9/9 - 0s - loss: 0.3879 - accuracy: 0.8430 - 30ms/epoch - 3ms/step\n",
            "Epoch 43/100\n",
            "9/9 - 0s - loss: 0.3855 - accuracy: 0.8430 - 24ms/epoch - 3ms/step\n",
            "Epoch 44/100\n",
            "9/9 - 0s - loss: 0.3835 - accuracy: 0.8388 - 21ms/epoch - 2ms/step\n",
            "Epoch 45/100\n",
            "9/9 - 0s - loss: 0.3821 - accuracy: 0.8430 - 28ms/epoch - 3ms/step\n",
            "Epoch 46/100\n",
            "9/9 - 0s - loss: 0.3803 - accuracy: 0.8471 - 27ms/epoch - 3ms/step\n",
            "Epoch 47/100\n",
            "9/9 - 0s - loss: 0.3786 - accuracy: 0.8471 - 31ms/epoch - 3ms/step\n",
            "Epoch 48/100\n",
            "9/9 - 0s - loss: 0.3770 - accuracy: 0.8471 - 26ms/epoch - 3ms/step\n",
            "Epoch 49/100\n",
            "9/9 - 0s - loss: 0.3753 - accuracy: 0.8471 - 24ms/epoch - 3ms/step\n",
            "Epoch 50/100\n",
            "9/9 - 0s - loss: 0.3744 - accuracy: 0.8471 - 23ms/epoch - 3ms/step\n",
            "Epoch 51/100\n",
            "9/9 - 0s - loss: 0.3721 - accuracy: 0.8512 - 27ms/epoch - 3ms/step\n",
            "Epoch 52/100\n",
            "9/9 - 0s - loss: 0.3708 - accuracy: 0.8512 - 24ms/epoch - 3ms/step\n",
            "Epoch 53/100\n",
            "9/9 - 0s - loss: 0.3694 - accuracy: 0.8512 - 24ms/epoch - 3ms/step\n",
            "Epoch 54/100\n",
            "9/9 - 0s - loss: 0.3708 - accuracy: 0.8430 - 17ms/epoch - 2ms/step\n",
            "Epoch 55/100\n",
            "9/9 - 0s - loss: 0.3705 - accuracy: 0.8388 - 21ms/epoch - 2ms/step\n",
            "Epoch 56/100\n",
            "9/9 - 0s - loss: 0.3686 - accuracy: 0.8430 - 19ms/epoch - 2ms/step\n",
            "Epoch 57/100\n",
            "9/9 - 0s - loss: 0.3658 - accuracy: 0.8471 - 27ms/epoch - 3ms/step\n",
            "Epoch 58/100\n",
            "9/9 - 0s - loss: 0.3640 - accuracy: 0.8595 - 21ms/epoch - 2ms/step\n",
            "Epoch 59/100\n",
            "9/9 - 0s - loss: 0.3626 - accuracy: 0.8595 - 29ms/epoch - 3ms/step\n",
            "Epoch 60/100\n",
            "9/9 - 0s - loss: 0.3611 - accuracy: 0.8554 - 23ms/epoch - 3ms/step\n",
            "Epoch 61/100\n",
            "9/9 - 0s - loss: 0.3605 - accuracy: 0.8554 - 24ms/epoch - 3ms/step\n",
            "Epoch 62/100\n",
            "9/9 - 0s - loss: 0.3600 - accuracy: 0.8471 - 32ms/epoch - 4ms/step\n",
            "Epoch 63/100\n",
            "9/9 - 0s - loss: 0.3611 - accuracy: 0.8554 - 22ms/epoch - 2ms/step\n",
            "Epoch 64/100\n",
            "9/9 - 0s - loss: 0.3594 - accuracy: 0.8512 - 28ms/epoch - 3ms/step\n",
            "Epoch 65/100\n",
            "9/9 - 0s - loss: 0.3568 - accuracy: 0.8595 - 29ms/epoch - 3ms/step\n",
            "Epoch 66/100\n",
            "9/9 - 0s - loss: 0.3553 - accuracy: 0.8595 - 28ms/epoch - 3ms/step\n",
            "Epoch 67/100\n",
            "9/9 - 0s - loss: 0.3539 - accuracy: 0.8554 - 34ms/epoch - 4ms/step\n",
            "Epoch 68/100\n",
            "9/9 - 0s - loss: 0.3532 - accuracy: 0.8554 - 26ms/epoch - 3ms/step\n",
            "Epoch 69/100\n",
            "9/9 - 0s - loss: 0.3518 - accuracy: 0.8554 - 26ms/epoch - 3ms/step\n",
            "Epoch 70/100\n",
            "9/9 - 0s - loss: 0.3512 - accuracy: 0.8595 - 22ms/epoch - 2ms/step\n",
            "Epoch 71/100\n",
            "9/9 - 0s - loss: 0.3512 - accuracy: 0.8595 - 23ms/epoch - 3ms/step\n",
            "Epoch 72/100\n",
            "9/9 - 0s - loss: 0.3496 - accuracy: 0.8595 - 33ms/epoch - 4ms/step\n",
            "Epoch 73/100\n",
            "9/9 - 0s - loss: 0.3495 - accuracy: 0.8554 - 25ms/epoch - 3ms/step\n",
            "Epoch 74/100\n",
            "9/9 - 0s - loss: 0.3474 - accuracy: 0.8512 - 25ms/epoch - 3ms/step\n",
            "Epoch 75/100\n",
            "9/9 - 0s - loss: 0.3481 - accuracy: 0.8471 - 37ms/epoch - 4ms/step\n",
            "Epoch 76/100\n",
            "9/9 - 0s - loss: 0.3482 - accuracy: 0.8471 - 33ms/epoch - 4ms/step\n",
            "Epoch 77/100\n",
            "9/9 - 0s - loss: 0.3475 - accuracy: 0.8512 - 25ms/epoch - 3ms/step\n",
            "Epoch 78/100\n",
            "9/9 - 0s - loss: 0.3460 - accuracy: 0.8554 - 26ms/epoch - 3ms/step\n",
            "Epoch 79/100\n",
            "9/9 - 0s - loss: 0.3453 - accuracy: 0.8512 - 20ms/epoch - 2ms/step\n",
            "Epoch 80/100\n",
            "9/9 - 0s - loss: 0.3439 - accuracy: 0.8554 - 27ms/epoch - 3ms/step\n",
            "Epoch 81/100\n",
            "9/9 - 0s - loss: 0.3430 - accuracy: 0.8554 - 27ms/epoch - 3ms/step\n",
            "Epoch 82/100\n",
            "9/9 - 0s - loss: 0.3424 - accuracy: 0.8554 - 24ms/epoch - 3ms/step\n",
            "Epoch 83/100\n",
            "9/9 - 0s - loss: 0.3420 - accuracy: 0.8554 - 34ms/epoch - 4ms/step\n",
            "Epoch 84/100\n",
            "9/9 - 0s - loss: 0.3403 - accuracy: 0.8595 - 30ms/epoch - 3ms/step\n",
            "Epoch 85/100\n",
            "9/9 - 0s - loss: 0.3402 - accuracy: 0.8595 - 20ms/epoch - 2ms/step\n",
            "Epoch 86/100\n",
            "9/9 - 0s - loss: 0.3400 - accuracy: 0.8636 - 17ms/epoch - 2ms/step\n",
            "Epoch 87/100\n",
            "9/9 - 0s - loss: 0.3395 - accuracy: 0.8636 - 22ms/epoch - 2ms/step\n",
            "Epoch 88/100\n",
            "9/9 - 0s - loss: 0.3384 - accuracy: 0.8636 - 27ms/epoch - 3ms/step\n",
            "Epoch 89/100\n",
            "9/9 - 0s - loss: 0.3380 - accuracy: 0.8595 - 22ms/epoch - 2ms/step\n",
            "Epoch 90/100\n",
            "9/9 - 0s - loss: 0.3363 - accuracy: 0.8636 - 29ms/epoch - 3ms/step\n",
            "Epoch 91/100\n",
            "9/9 - 0s - loss: 0.3361 - accuracy: 0.8636 - 29ms/epoch - 3ms/step\n",
            "Epoch 92/100\n",
            "9/9 - 0s - loss: 0.3362 - accuracy: 0.8595 - 23ms/epoch - 3ms/step\n",
            "Epoch 93/100\n",
            "9/9 - 0s - loss: 0.3367 - accuracy: 0.8554 - 19ms/epoch - 2ms/step\n",
            "Epoch 94/100\n",
            "9/9 - 0s - loss: 0.3347 - accuracy: 0.8636 - 20ms/epoch - 2ms/step\n",
            "Epoch 95/100\n",
            "9/9 - 0s - loss: 0.3331 - accuracy: 0.8678 - 19ms/epoch - 2ms/step\n",
            "Epoch 96/100\n",
            "9/9 - 0s - loss: 0.3336 - accuracy: 0.8678 - 24ms/epoch - 3ms/step\n",
            "Epoch 97/100\n",
            "9/9 - 0s - loss: 0.3329 - accuracy: 0.8678 - 35ms/epoch - 4ms/step\n",
            "Epoch 98/100\n",
            "9/9 - 0s - loss: 0.3328 - accuracy: 0.8678 - 37ms/epoch - 4ms/step\n",
            "Epoch 99/100\n",
            "9/9 - 0s - loss: 0.3320 - accuracy: 0.8678 - 23ms/epoch - 3ms/step\n",
            "Epoch 100/100\n",
            "9/9 - 0s - loss: 0.3315 - accuracy: 0.8678 - 29ms/epoch - 3ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f66fbd20d50>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_pred = nn_model.predict(X_test, batch_size = 30)\n",
        "nn_pred = n_pred.argmax(axis = 1)\n",
        "\n",
        "print_result(nn_model,nn_pred, X_train, y_train_nn, X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_j0Bp7H23OXO",
        "outputId": "e5b1f98c-70e2-4155-93a2-2c02dfbaec2f"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Result:\n",
            "================================================\n",
            "Accuracy Score: 88.52%\n",
            "_______________________________________________\n",
            "CLASSIFICATION REPORT:\n",
            "                   0          1  accuracy  macro avg  weighted avg\n",
            "precision   0.884615   0.885714  0.885246   0.885165      0.885228\n",
            "recall      0.851852   0.911765  0.885246   0.881808      0.885246\n",
            "f1-score    0.867925   0.898551  0.885246   0.883238      0.884995\n",
            "support    27.000000  34.000000  0.885246  61.000000     61.000000\n",
            "_______________________________________________\n",
            "Confusion Matrix: \n",
            " [[23  4]\n",
            " [ 3 31]]\n",
            "\n"
          ]
        }
      ]
    }
  ]
}